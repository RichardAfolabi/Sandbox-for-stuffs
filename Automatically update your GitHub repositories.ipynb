{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically update your GitHub repository everyday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to drop this `update_github.py` file in the parent directory containing all your `GitHub` repository. It doesn't have to be a repository itself. It's designed to read a folder/directory containing several other local repos.\n",
    "\n",
    "# Download the file here as `update_github.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All folders  in Parent Dir : \n",
      " ['.DS_Store', '.idea', '.ipynb_checkpoints', '_datasets_downloads', '_pydata-book-master', 'Data-Structures-Algorithms-in-Python', 'Data_Analysis_with_Python', 'Data_Science_Harvard', 'DataVisualization', 'for_pandas_video_tutorials', 'Machine_Learning_Python', 'Mining_Social_Network_Data', 'mybokeh', 'oreilly-intro-to-flask-video', 'python-web-scraping', 'Sandbox-for-stuffs', 'schedule_update_github.py', 'Scientific-Python', 'Templates', 'turaquo', 'update_github.py', 'update_mygithub.py', 'vidlix_analytics']\n",
      "\n",
      "GitHub folders : \n",
      "\n",
      " ['Data-Structures-Algorithms-in-Python', 'Data_Analysis_with_Python', 'Data_Science_Harvard', 'DataVisualization', 'Machine_Learning_Python', 'Mining_Social_Network_Data', 'oreilly-intro-to-flask-video', 'python-web-scraping', 'Sandbox-for-stuffs', 'Scientific-Python', 'Templates', 'turaquo']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "my_github_folders = []\n",
    "\n",
    "# parent_path = os.getcwd()                      # Remove this comment \n",
    "parent_path = \"/Users/RichardAfolabi/myGitHub/\"  # Comment this line\n",
    "\n",
    "\n",
    "all_folders = os.listdir(parent_path)\n",
    "\n",
    "print(\"\\n All folders  in Parent Dir : \\n\", all_folders)\n",
    "\n",
    "for test_path in all_folders:\n",
    "    git_folder = os.path.join(parent_path, test_path, \".git\")\n",
    "    if os.path.isdir(git_folder):\n",
    "        my_github_folders.append(test_path)\n",
    "\n",
    "\n",
    "print(\"\\nGitHub folders : \\n\\n\",my_github_folders)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's bulk update our repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 of 12 repos updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Let's count numbers of repository we updated\n",
    "repos_updated = 0\n",
    "\n",
    "# Get commands to execute\n",
    "gt_add = \"git add .\"\n",
    "gt_commit = \"git commit -m 'updated' \"\n",
    "gt_push = \"git push -u origin master\"\n",
    "\n",
    "# Push updates \n",
    "for repo in my_github_folders:\n",
    "    repo_path = os.path.join(parent_path, repo)\n",
    "    git_sequence = \"cd {0} && {1} && {2} && {3}\".format(repo_path, gt_add, gt_commit, gt_push)\n",
    "    if os.system(git_sequence) == 0:\n",
    "        repos_updated += 1\n",
    "        \n",
    "print(\"{0} of {1} repos updated successfully!\".format(repos_updated, len(my_github_folders)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Almost Finished!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you have it. We have successfully created a script that we run once and it automatically update our local and remote repositories!\n",
    "\n",
    "Now, if you're like me, you'll be thinking, how can I possibly fully automate this process and `schedule` the script as a `job` that runs by itself multiple times everyday?\n",
    "\n",
    "Yes!, you're right!\n",
    "\n",
    "That's what I've done on the next script below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Cron` job to automatically `update local repo`, `commit` and `push` to `remote` \n",
    "\n",
    "Here, we use a Python package called `Plan`\n",
    "Read Package Details:    http://plan.readthedocs.org/index.html\n",
    "\n",
    "Note that you first have to install the package..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plan\n",
      "  Using cached plan-0.5-py2.py3-none-any.whl\n",
      "Collecting click>=2.1 (from plan)\n",
      "  Using cached click-6.2-py2.py3-none-any.whl\n",
      "Installing collected packages: click, plan\n",
      "Successfully installed click-6.2 plan-0.5\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to install the required python package.\n",
    "! pip install plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save this as `cronjob.py`\n",
    "\n",
    "### Configure a python `cron` job that automatically runs our `update_github.py` script every `3 hours`. \n",
    "\n",
    "This means about `8 times` in `24 hours` which I think is sufficient to turn your `GitHub` heatmap to `Green`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from plan import Plan\n",
    "\n",
    "cron = Plan()\n",
    "\n",
    "cron.script('update_github.py', path=parent_path, every='3.hour')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cron.run('write')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### If you are using `Anaconda` Python distribution, behaviour of your `cron` job is determined by how you install your `anaconda`. \n",
    "\n",
    "### For some reason (I found out by accident and hours of tinkering), your `update_github.py` may run correctly with `python update_github.py` but when called in the `cron`, the python script is not called correctly. \n",
    "\n",
    "#### Solution is to do `source deactivate` on any `python environment` you have and only run on the `root` environment. Also, if you have `ipython` running, the environment may also affect your cron.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/RichardAfolabi/anaconda/envs/python3/bin/python /Users/RichardAfolabi/myGitHub/Sandbox-for-stuffs/geo_ip_job.py'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_path = \"/Users/RichardAfolabi/anaconda/envs/python3/bin/python \"\n",
    "job_path = os.path.join(os.getcwd(), \"geo_ip_job.py\")\n",
    "\n",
    "python_path + job_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
